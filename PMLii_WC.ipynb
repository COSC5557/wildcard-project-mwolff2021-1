{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C1IMjLNupsuG"
      },
      "outputs": [],
      "source": [
        "from pytorch import data\n",
        "\n",
        "x_tensor = torch.tensor(x.values)\n",
        "y_tensor = torch.tensor(y.values)\n",
        "\n",
        "target = x.values\n",
        "features = y.values\n",
        "\n",
        "criterion = torch.nn.MSELoss()\n",
        "trainloader = DataLoader(dataset=train_set, batch_size=1)\n",
        "\n",
        "learning_rates = [0.1, 0.01, 0.001, 0.0001]\n",
        "train_err = torch.zeros(len(learning_rates))\n",
        "val_err = torch.zeros(len(learning_rates))\n",
        "Models = []\n",
        "\n",
        "epochs = 20\n",
        "\n",
        "# iterate through the list of various learning rates\n",
        "for i, learning_rate in enumerate(learning_rates):\n",
        "    model = torch.nn.Linear(1, 1)\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)\n",
        "    for epoch in range(epochs):\n",
        "        for x, y in trainloader:\n",
        "            y_hat = model(x)\n",
        "            loss = criterion(y_hat, y)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "    # training data\n",
        "    Y_hat = model(train_set.x)\n",
        "    train_loss = criterion(Y_hat, train_set.y)\n",
        "    train_err[i] = train_loss.item()\n",
        "\n",
        "    # validation data\n",
        "    Y_hat = model(val_set.x)\n",
        "    val_loss = criterion(Y_hat, val_set.y)\n",
        "    val_err[i] = val_loss.item()\n",
        "\n",
        "# Passing to DataLoader\n",
        "train = data_utils.TensorDataset(features, target)\n",
        "train_loader = data_utils.DataLoader(train, batch_size=10, shuffle=True)\n",
        "\n",
        "print(X)\n",
        "logits = model(x)\n",
        "print(logits)\n",
        "pred_probab = nn.Softmax(dim=1)(logits)\n",
        "y_pred = pred_probab.argmax(1)\n",
        "print(f\"Predicted class: {y_pred}\")"
      ]
    }
  ]
}